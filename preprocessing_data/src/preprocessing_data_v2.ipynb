{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "\n",
    "in_file = \"../in_data/dossiers_journee-nationale-de-la-resilience-appel-a-projets_2023-08-01_16-59.xlsx\"\n",
    "\n",
    "df_dossier = pd.read_excel(in_file, sheet_name=\"Dossiers\")\n",
    "df_action_1 = pd.read_excel(in_file, sheet_name=\"(3344502) Action\") # actions ayant lieu qu'une fois\n",
    "df_action_2 = pd.read_excel(in_file, sheet_name=\"(3308253) Action\") # actions ayant lieu plusieurs fois\n",
    "df_loc_action2 = pd.read_excel(in_file, sheet_name=\"(3308215) Localisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les données nécessaires de l'onglet \"Dossiers\"\n",
    "\n",
    "df_dossier = df_dossier[[\"ID\", \"Sélectionnez la zone géographique du projet\", \"Raison sociale\", \"État du dossier\"]].rename(columns={\"Raison sociale\":\"Organisateur\", \"Sélectionnez la zone géographique du projet\": \"Zone géographique\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association de l'adresse aux action se déroulant plusieurs fois\n",
    "# Uniquement possible si une seule action\n",
    "\n",
    "# On compte le nombre d'actions par dossier\n",
    "nb_action_2 = df_action_2[\"Dossier ID\"].value_counts().rename(\"Nb actions\").to_frame()\n",
    "dossier_id_valides = nb_action_2[nb_action_2[\"Nb actions\"] == 1].index.to_list()\n",
    "\n",
    "# On filtre les dossiers valides\n",
    "df_action_2 = df_action_2[df_action_2[\"Dossier ID\"].isin(dossier_id_valides)]\n",
    "df_loc_action2 = df_loc_action2[df_loc_action2[\"Dossier ID\"].isin(dossier_id_valides)]\n",
    "\n",
    "# On supprime les colonnes en doublon\n",
    "df_action_2 = df_action_2.drop(columns=[\"Ligne\",\"Nom de l'action\"])\n",
    "\n",
    "# On fusionne les deux jeux de données pour récupérer les adresses\n",
    "df_action_2 = pd.merge(df_loc_action2, df_action_2, how=\"left\", on=\"Dossier ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     92\n",
       "1     92\n",
       "2    972\n",
       "3     17\n",
       "4    971\n",
       "5     85\n",
       "6     93\n",
       "Name: Zone géographique, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export des actions dématerialisées (et grand public)\n",
    "df_action_demat = df_action_1 = df_action_1[\n",
    "    (~df_action_1[\"Nom de l'action\"].isna()) &\n",
    "    (df_action_1[\"L'action est-elle ouverte au grand public ?\"] == \"Oui\") &\n",
    "    (df_action_1[\"Votre action est-elle dématérialisée ?\"] == \"Oui\")\n",
    "]\n",
    "\n",
    "df_action_demat = pd.merge(\n",
    "    df_action_demat, \n",
    "    df_dossier, \n",
    "    how=\"left\", right_on=\"ID\", left_on=\"Dossier ID\"\n",
    "    )\n",
    "\n",
    "# Extraction de la zone géographique \n",
    "# Ici que pour départements\n",
    "df_action_demat[\"Zone géographique\"]= pd.Series([l[0] for l in df_action_demat[\"Zone géographique\"].str.split(\"-\")])\n",
    "df_action_demat[\"Zone géographique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les actions :\n",
    "# - Renseignées\n",
    "# - Grand public\n",
    "# - Non dématerialisées\n",
    "\n",
    "df_action_1 = df_action_1[\n",
    "    (~df_action_1[\"Nom de l'action\"].isna()) &\n",
    "    (df_action_1[\"L'action est-elle ouverte au grand public ?\"] == \"Oui\") &\n",
    "    (df_action_1[\"Votre action est-elle dématérialisée ?\"] == \"Non\")\n",
    "]\n",
    "\n",
    "df_action_2 = df_action_2[\n",
    "    (~df_action_2[\"Nom de l'action\"].isna()) &\n",
    "    (df_action_2[\"L'action est-elle ouverte au grand public ?\"] == \"Oui\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du code de département\n",
    "df_action_2.loc[df_action_2[\"Département de l'action\"].isna()][\"Département de l'action\"] = df_action_2[df_action_2[\"Département de l'action\"].isna()][\"Commune de l'action (Département)\"].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des colonnes intéressantes\n",
    "# Changement de nom pour fusionner les deux jeux de données\n",
    "# Filtrer : action grand public ET non dématérialisée\n",
    "\n",
    "df_action_1 = df_action_1[[\n",
    "    \"Dossier ID\", \"Ligne\",\n",
    "    \"Nom de l'action\", \"Description de l'action\",\n",
    "    \"Risques ciblés\", \"Risques naturels\", \"Risques technologiques\",\n",
    "    \"Public cible\",\n",
    "    \"Date prévisionnelle du début de l'action\", \"Date prévisionnelle de la fin de l'action\",\n",
    "    \"Veuillez indiquer l'adresse complète de l'action\", \"Commune\", \"Département (Code)\", \"Département\"\n",
    "    ]].rename(columns={\n",
    "        \"Nom de l'action\" : \"Nom\", \n",
    "        \"Description de l'action\" : \"Description\",\n",
    "        \"Date prévisionnelle du début de l'action\" : \"Date début\", \n",
    "        \"Date prévisionnelle de la fin de l'action\" : \"Date fin\",\n",
    "        \"Veuillez indiquer l'adresse complète de l'action\" : \"Adresse\", \n",
    "        \"Commune\" : \"Nom commune\", \n",
    "        \"Département (Code)\" : \"INSEE_DEP\",\n",
    "    })\n",
    "\n",
    "# df_action_1_ = df_action_1_.assign(origine=\"Action 1\")\n",
    "\n",
    "df_action_2 = df_action_2[[\n",
    "    \"Dossier ID\", \"Ligne\",\n",
    "    \"Nom de l'action\", \"Description de l'action\",\n",
    "    \"Risques ciblés\", \"Risques naturels\", \"Risques technologiques\",\n",
    "    \"Public cible\",\n",
    "    \"Date prévisionnelle du début de l'action\", \"Date prévisionnelle de la fin de l'action\",\n",
    "    \"Adressse complète de l'action\", \"Commune de l'action\", \"Département de l'action (Code)\", \"Département de l'action\"\n",
    "    ]].rename(columns={\n",
    "        \"Nom de l'action\" : \"Nom\", \n",
    "        \"Description de l'action\" : \"Description\",\n",
    "        \"Date prévisionnelle du début de l'action\" : \"Date début\", \n",
    "        \"Date prévisionnelle de la fin de l'action\" : \"Date fin\",\n",
    "        \"Adressse complète de l'action\" : \"Adresse\", \n",
    "        \"Commune de l'action\" : \"Nom commune\", \n",
    "        \"Département de l'action (Code)\" : \"INSEE_DEP\",\n",
    "        \"Département de l'action\" : \"Département\"\n",
    "    })\n",
    "\n",
    "# df_action_2 = df_action_2.assign(origine=\"Action 2\")\n",
    "\n",
    "# Concatenation des jeux de données\n",
    "df_action = pd.concat((df_action_1,df_action_2))\n",
    "\n",
    "# Récupération des informations dossier\n",
    "df_action = pd.merge(df_action, df_dossier, how=\"left\", left_on=\"Dossier ID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "22\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(df_action_1))\n",
    "print(len(df_action_2))\n",
    "print(len(df_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction des champs True/False\n",
    "\n",
    "def traitement_champs_multiples(df, col, choix, fillna = False):\n",
    "    \"\"\"Conversion des champs à choix multiples en plusieurs champs True / False\"\"\"\n",
    "    \n",
    "    for c in choix : \n",
    "        df[\"Est \"+c] = df.apply(\n",
    "            lambda x : fillna if not(isinstance(x[col],str)) else (c in x[col].split(\", \")),\n",
    "            axis = 1\n",
    "        )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col,choix in [\n",
    "    (\"Risques ciblés\", [\"Risques naturels\",\"Risques technologiques\"]),\n",
    "    (\"Risques naturels\", [\"Inondations\",\"Feux de forêt\",\"Tempête/cyclone\",\"Séisme\",\"Éruption volcanique\",\"Mouvement de terrain\",\"Risques littoraux\",\"Avalanche\",\"Radon\"]),\n",
    "    (\"Risques technologiques\", [\"Accidents industriels\",\"Accidents nucléaires\",\"Rupture de barrage\",\"Transport de matières dangereuses\"]),\n",
    "    (\"Public cible\", [\"Tous public\",\"Famille\",\"Jeune public\",\"Séniors\"]),\n",
    "] :\n",
    "    df_action = traitement_champs_multiples(df_action, col, choix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : L'adresse suivante n'a pas été trouvée : Ecole Mixte 1, Guyonneau 97116 Pointe-Noire, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : SITE DE LA VILLE DE CHOELCHER, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Longvilliers Club - Petit manoir - 97232 LE LAMENTIN, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : foyer théâtre,  2 Rue du Foyer, 11700 Douzens, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Chemin du vallon 74140 Loisin, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Chemin du vallon 74140 Loisin, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Chemin du vallon 74140 Loisin, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Boulevard Militaire - Salle du Manège, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Boulevard Militaire - Salle du Manège, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Boulevard de la baie de Txingudi 64700 Hendaye (RDV précisé au moment de l'inscription), on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Chemin des Etangs 19450 Chamboulive, on donne les coordonnées de la commune\n",
      "Warning : Commune Chamboulive (19450) (nan) non trouvée\n",
      "Warning : L'adresse suivante n'a pas été trouvée : route de l'étang 19800 Meyrignac-l'Église, on donne les coordonnées de la commune\n",
      "Warning : Commune Meyrignac-l’Église (19800) (nan) non trouvée\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Etang de Miel 19190 Beynat, on donne les coordonnées de la commune\n",
      "Warning : Commune Beynat (19190) (nan) non trouvée\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Zac Étang Z Abricot 97200 Fort-de-France, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Le Bourg Nord 97220 La Trinité, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Cite Ozanam Bateliere 97233 Schœlcher, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Moudong Sud 97122 Baie-Mahault, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Bd du Marquisat du Houelbourg 97122 Baie-Mahault, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : 18 Boulevard Hegesippe Legitimus 97110 Pointe-à-Pitre, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Micro-Folie/ Théâtre de Duclair Place du Géneral de Gaulle 76480 Duclair, on donne les coordonnées de la commune\n",
      "Warning : L'adresse suivante n'a pas été trouvée : Ecole André Malraux 222 rue Victor Hugo - 76480 Duclai, on donne les coordonnées de la commune\n"
     ]
    }
   ],
   "source": [
    "# Détermination des coordonnées des actions\n",
    "\n",
    "# Récolte des coordonnées et département pour actions\n",
    "\n",
    "def adress2latlon(adress, commune, dpt):\n",
    "    \n",
    "    \"\"\"Interroge l'API de recherche d'adresse de OpenStreetMap\n",
    "    - Si adresse non rentrée par le dépositaire du dossier OU non trouvée par OpenStreetMap : on cherche les coordonnées de la commune\n",
    "    - Sinon on donne les coordonnées de l'adresse précise\n",
    "    \"\"\"\n",
    "    \n",
    "    if not(isinstance(adress, str)):\n",
    "        return [np.nan,np.nan]\n",
    "    \n",
    "    url = f\"https://nominatim.openstreetmap.org/?adressdetails=1&q={adress.replace(' ','+')}&format=json&limit=1\"\n",
    "    \n",
    "    try :\n",
    "        \n",
    "        data = requests.get(url).json()[0]\n",
    "                \n",
    "        # commune = data[\"display_name\"].split(\", \")[2]\n",
    "        # dpt = data[\"display_name\"].split(\", \")[4]\n",
    "\n",
    "        return [data[\"lat\"],data[\"lon\"]]\n",
    "    \n",
    "    except :\n",
    "        print(f\"Warning : L'adresse suivante n'a pas été trouvée : {adress}, on donne les coordonnées de la commune\")\n",
    "        \n",
    "        url = f\"https://nominatim.openstreetmap.org/?adressdetails=1&q={commune.replace(' ','+')},+{dpt}&format=json&limit=1\"\n",
    "\n",
    "        try : \n",
    "            data = requests.get(url).json()[0]\n",
    "            return [data[\"lat\"],data[\"lon\"]]\n",
    "        \n",
    "        except :\n",
    "            print(f\"Warning : Commune {commune} ({dpt}) non trouvée\")\n",
    "            return [np.nan,np.nan]\n",
    "            \n",
    "df_action[['Lat', 'Lon']] = pd.DataFrame([adress2latlon(adress,com,dpt) for adress,com,dpt in zip(df_action[\"Adresse\"],df_action[\"Nom commune\"],df_action[\"Département\"])],index=df_action.index)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : les coordonnées de 3 actions n'ont pas pu être déterminées.\n"
     ]
    }
   ],
   "source": [
    "# # On filtre les actions dont les coordonnées n'ont pas été trouvée\n",
    "\n",
    "print(f\"Warning : les coordonnées de {df_action['Lat'].isna().sum()} actions n'ont pas pu être déterminées.\")\n",
    "df_action = df_action[~df_action['Lat'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Dossier ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Dossier ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Export des données pour la carte\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df_action \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39massign(\n\u001b[0;32m      4\u001b[0m     action_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m      5\u001b[0m     )\n\u001b[1;32m----> 7\u001b[0m df_action[\u001b[39m\"\u001b[39m\u001b[39maction_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m      8\u001b[0m     \u001b[39mlambda\u001b[39;49;00m r : \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mr[\u001b[39m\"\u001b[39;49m\u001b[39mDossier ID\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mr[\u001b[39m\"\u001b[39;49m\u001b[39mLigne\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m:\u001b[39;49;00m\u001b[39m02d\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m df_action \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mLigne\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m df_action \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(df_action\u001b[39m.\u001b[39mcolumns, [unidecode(c)\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m df_action\u001b[39m.\u001b[39mcolumns])))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Export des données pour la carte\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df_action \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39massign(\n\u001b[0;32m      4\u001b[0m     action_id \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m      5\u001b[0m     )\n\u001b[0;32m      7\u001b[0m df_action[\u001b[39m\"\u001b[39m\u001b[39maction_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39mapply(\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mlambda\u001b[39;00m r : \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mr[\u001b[39m\"\u001b[39m\u001b[39mDossier ID\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mr[\u001b[39m\"\u001b[39m\u001b[39mLigne\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m02d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m df_action \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mLigne\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m df_action \u001b[39m=\u001b[39m df_action\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(df_action\u001b[39m.\u001b[39mcolumns, [unidecode(c)\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m df_action\u001b[39m.\u001b[39mcolumns])))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Dossier ID'"
     ]
    }
   ],
   "source": [
    "# Export des données pour la carte\n",
    "\n",
    "df_action = df_action.assign(\n",
    "    action_id = np.nan\n",
    "    )\n",
    "\n",
    "df_action[\"action_id\"] = df_action.apply(\n",
    "    lambda r : f'{r[\"Dossier ID\"]}_{r[\"Ligne\"]:02d}', axis=1\n",
    ")\n",
    "\n",
    "df_action = df_action.drop(columns=[\"Ligne\"])\n",
    "\n",
    "df_action = df_action.rename(columns=dict(zip(df_action.columns, [unidecode(c).lower().replace(\" \",\"_\").replace(\"/\",\"_\") for c in df_action.columns])))\n",
    "\n",
    "df_action.to_csv(\n",
    "    \"../out_data/actions_grand_public_carte.csv\", index=False\n",
    ")\n",
    "\n",
    "df_action.to_csv(\n",
    "    \"../out_data/actions_grand_public_carte_ansi.csv\", index=False, sep=\";\", encoding=\"ansi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action.to_csv(\n",
    "    \"../out_data/actions_grand_public_carte.csv\", index=False\n",
    ")\n",
    "\n",
    "df_action.to_csv(\n",
    "    \"../out_data/actions_grand_public_carte_ansi.csv\", index=False, sep=\";\", encoding=\"ansi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{int(1.):02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dossier_id</th>\n",
       "      <th>nom</th>\n",
       "      <th>description</th>\n",
       "      <th>risques_cibles</th>\n",
       "      <th>risques_naturels</th>\n",
       "      <th>risques_technologiques</th>\n",
       "      <th>public_cible</th>\n",
       "      <th>date_debut</th>\n",
       "      <th>date_fin</th>\n",
       "      <th>adresse</th>\n",
       "      <th>...</th>\n",
       "      <th>est_accidents_nucleaires</th>\n",
       "      <th>est_rupture_de_barrage</th>\n",
       "      <th>est_transport_de_matieres_dangereuses</th>\n",
       "      <th>est_tous_public</th>\n",
       "      <th>est_famille</th>\n",
       "      <th>est_jeune_public</th>\n",
       "      <th>est_seniors</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>action_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13002567</td>\n",
       "      <td>Ateliers éducatifs autour des étangs</td>\n",
       "      <td>Informer sur la prise en compte du risque de r...</td>\n",
       "      <td>Risques naturels</td>\n",
       "      <td>Inondations, Feux de forêt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tous public</td>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>route du Lac 19300 Égletons</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45.4168778</td>\n",
       "      <td>2.0584588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dossier_id                                    nom  \\\n",
       "29    13002567  Ateliers éducatifs autour des étangs    \n",
       "\n",
       "                                          description    risques_cibles  \\\n",
       "29  Informer sur la prise en compte du risque de r...  Risques naturels   \n",
       "\n",
       "              risques_naturels risques_technologiques public_cible  \\\n",
       "29  Inondations, Feux de forêt                    NaN  Tous public   \n",
       "\n",
       "    date_debut    date_fin                      adresse  ...  \\\n",
       "29  2023-10-09  2023-10-13  route du Lac 19300 Égletons  ...   \n",
       "\n",
       "   est_accidents_nucleaires  est_rupture_de_barrage  \\\n",
       "29                    False                   False   \n",
       "\n",
       "   est_transport_de_matieres_dangereuses  est_tous_public est_famille  \\\n",
       "29                                 False             True       False   \n",
       "\n",
       "   est_jeune_public  est_seniors         lat        lon  action_id  \n",
       "29            False        False  45.4168778  2.0584588        NaN  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation des données au niveau départemental \n",
    "\n",
    "# On retire les actions pour lesquelles le département n'est pas indiqué\n",
    "df_action = df_action[~df_action[\"insee_dep\"].isna()]\n",
    "\n",
    "# On s'assure de convertir les codes de département en chaînes de caractère valables\n",
    "if df_action[\"insee_dep\"].dtype == float:\n",
    "    df_action[\"insee_dep\"] = df_action.apply(lambda r : f\"{int(r['insee_dep']):02d}\", axis=1)\n",
    "\n",
    "# On retient que les actions ouvertes au grand public \n",
    "\n",
    "risques = [\"Inondations\",\"Feux de forêt\",\"Tempête/cyclone\",\"Séisme\",\"Éruption volcanique\",\"Mouvement de terrain\",\"Risques littoraux\",\"Avalanche\",\"Radon\",\"Accidents industriels\",\"Accidents nucléaires\",\"Rupture de barrage\",\"Transport de matières dangereuses\"]\n",
    "col_risques = [f\"est_{unidecode(c).lower().replace(' ','_').replace('/','_')}\" for c in risques]\n",
    "\n",
    "df_nb_actions_risque = df_action.groupby(\"insee_dep\")[col_risques].sum()\n",
    "df_nb_actions = df_action[\"insee_dep\"].value_counts()\n",
    "\n",
    "nb_actions_risque_dict = {}\n",
    "\n",
    "couleurs_risques = {\n",
    "    \"Inondations\" : \"#74BFDF\",\n",
    "    \"Feux de forêt\" : \"#FC7C7C\",\n",
    "    \"Tempête/cyclone\" : \"#B4CAD3\",\n",
    "    \"Séisme\" : \"#D3C7B4\",\n",
    "    \"Éruption volcanique\" : \"#FFB475\",\n",
    "    \"Mouvement de terrain\" : \"#A87C56\",\n",
    "    \"Risques littoraux\" : \"#A9FBF7\",\n",
    "    \"Avalanche\" : \"#E4E6E6\",\n",
    "    \"Radon\" : \"#FDC7FD\",\n",
    "    \"Accidents industriels\" : \"#B862F5\",\n",
    "    \"Accidents nucléaires\" : \"#F2ED5A\",\n",
    "    \"Rupture de barrage\" : \"#4046F5\",\n",
    "    \"Transport de matières dangereuses\" : \"#F75CA9\"\n",
    "}\n",
    "\n",
    "couleurs = [couleurs_risques[r] for r in risques]\n",
    "\n",
    "# Données INSEE\n",
    "insee_data_dir = \"../in_data\"\n",
    "df_dpt = pd.read_csv(os.path.join(insee_data_dir, \"DEPARTEMENT.csv\"))\n",
    "\n",
    "for code in df_dpt[\"INSEE_DEP\"]:\n",
    "    nb_actions_risque_dict[code] = {\n",
    "        \"Nombre actions\" : 0\n",
    "    }\n",
    "\n",
    "for code in df_nb_actions.index:\n",
    "    try : \n",
    "        nb_actions_risque_dict[code][\"Nombre actions\"] = df_nb_actions.loc[code].item()\n",
    "    except KeyError:\n",
    "        print(f\"Entrées régionales non prises en compte pour le moment (région {code})\")\n",
    "\n",
    "for code in df_nb_actions_risque.index:\n",
    "    try :\n",
    "        data = df_nb_actions_risque.loc[code].values.flatten()\n",
    "        data_dpt = nb_actions_risque_dict[code]\n",
    "        data_dpt[\"Type de risque\"] = np.array(risques)[data!=0].tolist()\n",
    "        data_dpt[\"Nombre d'actions\"] = data[data!=0].tolist()\n",
    "        data_dpt[\"couleur_plot\"] = np.array(couleurs)[data!=0].tolist()\n",
    "    except KeyError:\n",
    "        print(f\"Entrées régionales non prises en compte pour le moment (région {code})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../out_data/nb_actions_dpt_08_07_new_names.json', 'w') as fp:\n",
    "    json.dump(nb_actions_risque_dict, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict({\"A\":[1,2.],\"B\":[\"a\",\"b\"]})\n",
    "df2 = pd.DataFrame.from_dict({\"A\":[1,2.,3],\"C\":[\"A\",\"B\",\"C\"], \"D\":[\"A\",\"B\",\"C\"]})\n",
    "\n",
    "df3 = pd.merge(df1, df2, how=\"left\", on=\"A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  B  C  D\n",
       "0  1.0  a  A  A\n",
       "1  2.0  b  B  B"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
